{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11970722,"sourceType":"datasetVersion","datasetId":7527603}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Install Datasets Library\n\nInstalls Hugging Face’s `datasets` to access the FinQA dataset.\n","metadata":{}},{"cell_type":"code","source":"!pip install datasets\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FvmA98kZdeRE","outputId":"09123f0e-f728-4a67-ea22-52eb8355bd2b","trusted":true,"execution":{"iopub.status.busy":"2025-06-03T12:33:34.361019Z","iopub.execute_input":"2025-06-03T12:33:34.361434Z","iopub.status.idle":"2025-06-03T12:33:39.433224Z","shell.execute_reply.started":"2025-06-03T12:33:34.361414Z","shell.execute_reply":"2025-06-03T12:33:39.432319Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2024.12.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## 2. Load the FinQA Dataset\n\nLoads the FinQA dataset from Hugging Face using `load_dataset`. This gives access to the training, validation, and test splits.\n","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"ibm-research/finqa\", trust_remote_code=True)\n\n","metadata":{"id":"kgGZyhoHdjqG","trusted":true,"execution":{"iopub.status.busy":"2025-06-03T12:33:51.752928Z","iopub.execute_input":"2025-06-03T12:33:51.753257Z","iopub.status.idle":"2025-06-03T12:33:57.728276Z","shell.execute_reply.started":"2025-06-03T12:33:51.753232Z","shell.execute_reply":"2025-06-03T12:33:57.727675Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04500b52885f44d6a54b9fe7a2b4f44c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"finqa.py:   0%|          | 0.00/4.49k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a560c83156d845e58531300036f5f644"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/21.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1d4d360f603455ba9a397cd88357f3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17c9bc99967244158334c4d79643644a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e5192b04fe04fa1948c691b611a0f4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1767f041761146959478436e53b15a06"}},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"## 3. Inspect the Dataset\n\nPrints the dataset structure and previews one training sample to understand the available fields (e.g., question, table, program, answer).\n","metadata":{}},{"cell_type":"code","source":"# Check dataset structure\nprint(dataset)\n\n# View a sample entry\nsample = dataset['train'][0]\nfor key, value in sample.items():\n    print(f\"{key}: {value}\\n\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O83T0KUbe9V1","outputId":"0c288453-8669-4fb1-af12-054816ea329d","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T07:13:05.142791Z","iopub.execute_input":"2025-05-27T07:13:05.143136Z","iopub.status.idle":"2025-05-27T07:13:05.148798Z","shell.execute_reply.started":"2025-05-27T07:13:05.143111Z","shell.execute_reply":"2025-05-27T07:13:05.147874Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'pre_text', 'post_text', 'table', 'question', 'answer', 'final_result', 'program_re', 'gold_inds'],\n        num_rows: 6251\n    })\n    validation: Dataset({\n        features: ['id', 'pre_text', 'post_text', 'table', 'question', 'answer', 'final_result', 'program_re', 'gold_inds'],\n        num_rows: 883\n    })\n    test: Dataset({\n        features: ['id', 'pre_text', 'post_text', 'table', 'question', 'answer', 'final_result', 'program_re', 'gold_inds'],\n        num_rows: 1147\n    })\n})\nid: ADI/2009/page_49.pdf-1\n\npre_text: ['interest rate to a variable interest rate based on the three-month libor plus 2.05% ( 2.05 % ) ( 2.34% ( 2.34 % ) as of october 31 , 2009 ) .', 'if libor changes by 100 basis points , our annual interest expense would change by $ 3.8 million .', 'foreign currency exposure as more fully described in note 2i .', 'in the notes to consolidated financial statements contained in item 8 of this annual report on form 10-k , we regularly hedge our non-u.s .', 'dollar-based exposures by entering into forward foreign currency exchange contracts .', 'the terms of these contracts are for periods matching the duration of the underlying exposure and generally range from one month to twelve months .', 'currently , our largest foreign currency exposure is the euro , primarily because our european operations have the highest proportion of our local currency denominated expenses .', 'relative to foreign currency exposures existing at october 31 , 2009 and november 1 , 2008 , a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates over the course of the year would not expose us to significant losses in earnings or cash flows because we hedge a high proportion of our year-end exposures against fluctuations in foreign currency exchange rates .', 'the market risk associated with our derivative instruments results from currency exchange rate or interest rate movements that are expected to offset the market risk of the underlying transactions , assets and liabilities being hedged .', 'the counterparties to the agreements relating to our foreign exchange instruments consist of a number of major international financial institutions with high credit ratings .', 'we do not believe that there is significant risk of nonperformance by these counterparties because we continually monitor the credit ratings of such counterparties .', 'while the contract or notional amounts of derivative financial instruments provide one measure of the volume of these transactions , they do not represent the amount of our exposure to credit risk .', 'the amounts potentially subject to credit risk ( arising from the possible inability of counterparties to meet the terms of their contracts ) are generally limited to the amounts , if any , by which the counterparties 2019 obligations under the contracts exceed our obligations to the counterparties .', 'the following table illustrates the effect that a 10% ( 10 % ) unfavorable or favorable movement in foreign currency exchange rates , relative to the u.s .', 'dollar , would have on the fair value of our forward exchange contracts as of october 31 , 2009 and november 1 , 2008: .']\n\npost_text: ['fair value of forward exchange contracts after a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates asset ( liability ) .', '.', '.', '.', '.', '.', '.', '.', '.', '$ 20132 $ ( 9457 ) fair value of forward exchange contracts after a 10% ( 10 % ) favorable movement in foreign currency exchange rates liability .', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '$ ( 6781 ) $ ( 38294 ) the calculation assumes that each exchange rate would change in the same direction relative to the u.s .', 'dollar .', 'in addition to the direct effects of changes in exchange rates , such changes typically affect the volume of sales or the foreign currency sales price as competitors 2019 products become more or less attractive .', 'our sensitivity analysis of the effects of changes in foreign currency exchange rates does not factor in a potential change in sales levels or local currency selling prices. .']\n\ntable: [['', 'october 31 2009', 'november 1 2008'], ['fair value of forward exchange contracts asset ( liability )', '$ 6427', '$ -23158 ( 23158 )'], ['fair value of forward exchange contracts after a 10% ( 10 % ) unfavorable movement in foreign currency exchange rates asset ( liability )', '$ 20132', '$ -9457 ( 9457 )'], ['fair value of forward exchange contracts after a 10% ( 10 % ) favorable movement in foreign currency exchange rates liability', '$ -6781 ( 6781 )', '$ -38294 ( 38294 )']]\n\nquestion: what is the the interest expense in 2009?\n\nanswer: 380\n\nfinal_result: 380\n\nprogram_re: divide(100, 100), divide(3.8, #0)\n\ngold_inds: ['if libor changes by 100 basis points , our annual interest expense would change by $ 3.8 million .']\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## 4. View a Random Training Sample\n\nDisplays a random entry from the training set to explore the variety of questions and table structures in FinQA.\n","metadata":{}},{"cell_type":"code","source":"from random import randint\n\n# View a random sample from the training set\ni = randint(0, len(dataset['train']) - 1)\nsample = dataset['train'][i]\n\nfor k, v in sample.items():\n    print(f\"\\n{k.upper()}:\\n{v}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lwkMOnYgffe","outputId":"f2066919-56fc-4c76-9ac1-75a3ce9f4a3f","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T07:13:21.807169Z","iopub.execute_input":"2025-05-27T07:13:21.807734Z","iopub.status.idle":"2025-05-27T07:13:21.813063Z","shell.execute_reply.started":"2025-05-27T07:13:21.807710Z","shell.execute_reply":"2025-05-27T07:13:21.812149Z"}},"outputs":[{"name":"stdout","text":"\nID:\nLMT/2013/page_49.pdf-3\n\nPRE_TEXT:\n['frequency ( aehf ) system , orion , global positioning satellite ( gps ) iii system , geostationary operational environmental satellite r-series ( goes-r ) , and mobile user objective system ( muos ) .', 'operating profit for our space systems business segment includes our share of earnings for our investment in united launch alliance ( ula ) , which provides expendable launch services to the u.s .', 'government .', 'space systems 2019 operating results included the following ( in millions ) : .']\n\nPOST_TEXT:\n['2013 compared to 2012 space systems 2019 net sales for 2013 decreased $ 389 million , or 5% ( 5 % ) , compared to 2012 .', 'the decrease was primarily attributable to lower net sales of approximately $ 305 million for commercial satellite programs due to fewer deliveries ( zero delivered during 2013 compared to two for 2012 ) ; and about $ 290 million for the orion program due to lower volume .', 'the decreases were partially offset by higher net sales of approximately $ 130 million for government satellite programs due to net increased volume ; and about $ 65 million for strategic and defensive missile programs ( primarily fbm ) due to increased volume and risk retirements .', 'the increase for government satellite programs was primarily attributable to higher volume on aehf and other programs , partially offset by lower volume on goes-r , muos , and sbirs programs .', 'space systems 2019 operating profit for 2013 decreased $ 38 million , or 4% ( 4 % ) , compared to 2012 .', 'the decrease was primarily attributable to lower operating profit of approximately $ 50 million for the orion program due to lower volume and risk retirements and about $ 30 million for government satellite programs due to decreased risk retirements , which were partially offset by higher equity earnings from joint ventures of approximately $ 35 million .', 'the decrease in operating profit for government satellite programs was primarily attributable to lower risk retirements for muos , gps iii , and other programs , partially offset by higher risk retirements for the sbirs and aehf programs .', 'operating profit for 2013 included about $ 15 million of charges , net of recoveries , related to the november 2013 restructuring plan .', 'adjustments not related to volume , including net profit booking rate adjustments and other matters , were approximately $ 15 million lower for 2013 compared to 2012 .', '2012 compared to 2011 space systems 2019 net sales for 2012 increased $ 186 million , or 2% ( 2 % ) , compared to 2011 .', 'the increase was attributable to higher net sales of approximately $ 150 million due to increased commercial satellite deliveries ( two commercial satellites delivered in 2012 compared to one during 2011 ) ; about $ 125 million from the orion program due to higher volume and an increase in risk retirements ; and approximately $ 70 million from increased volume on various strategic and defensive missile programs .', 'partially offsetting the increases were lower net sales of approximately $ 105 million from certain government satellite programs ( primarily sbirs and muos ) as a result of decreased volume and a decline in risk retirements ; and about $ 55 million from the nasa external tank program , which ended in connection with the completion of the space shuttle program in 2011 .', 'space systems 2019 operating profit for 2012 increased $ 20 million , or 2% ( 2 % ) , compared to 2011 .', 'the increase was attributable to higher operating profit of approximately $ 60 million from commercial satellite programs due to increased deliveries and reserves recorded in 2011 ; and about $ 40 million from the orion program due to higher risk retirements and increased volume .', 'partially offsetting the increases was lower operating profit of approximately $ 45 million from lower volume and risk retirements on certain government satellite programs ( primarily sbirs ) ; about $ 20 million from lower risk retirements and lower volume on the nasa external tank program , which ended in connection with the completion of the space shuttle program in 2011 ; and approximately $ 20 million from lower equity earnings as a decline in launch related activities at ula partially was offset by the resolution of contract cost matters associated with the wind-down of united space alliance ( usa ) .', 'adjustments not related to volume , including net profit booking rate adjustments described above , were approximately $ 15 million higher for 2012 compared to 2011 .', 'equity earnings total equity earnings recognized by space systems ( primarily ula in 2013 ) represented approximately $ 300 million , or 29% ( 29 % ) of this segment 2019s operating profit during 2013 .', 'during 2012 and 2011 , total equity earnings recognized by space systems from ula , usa , and the u.k .', 'atomic weapons establishment joint venture represented approximately $ 265 million and $ 285 million , or 24% ( 24 % ) and 27% ( 27 % ) of this segment 2019s operating profit. .']\n\nTABLE:\n[['', '2013', '2012', '2011'], ['net sales', '$ 7958', '$ 8347', '$ 8161'], ['operating profit', '1045', '1083', '1063'], ['operating margins', '13.1% ( 13.1 % )', '13.0% ( 13.0 % )', '13.0% ( 13.0 % )'], ['backlog at year-end', '20500', '18100', '16000']]\n\nQUESTION:\nwhat was the average net sales from 2011 to 2013\n\nANSWER:\n8155.3\n\nFINAL_RESULT:\n8155.33\n\nPROGRAM_RE:\nadd(7958, 8347), add(#0, 8161), add(#1, const_3), divide(#2, const_2)\n\nGOLD_INDS:\n['the net sales of 2013 is $ 7958 ; the net sales of 2012 is $ 8347 ; the net sales of 2011 is $ 8161 ;']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## 5. Convert Table Data to DataFrame\n\nTransforms the raw table from the sample into a readable pandas DataFrame for easier viewing and analysis.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nsample = dataset['train'][i]  # use same i from before\ntable = pd.DataFrame(sample['table'][1:], columns=sample['table'][0])\ntable\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":331},"id":"0QYBfEHbgfkD","outputId":"ef783bc4-79ce-483f-9d58-db99ea76a167","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T07:13:27.444177Z","iopub.execute_input":"2025-05-27T07:13:27.444448Z","iopub.status.idle":"2025-05-27T07:13:27.468562Z","shell.execute_reply.started":"2025-05-27T07:13:27.444429Z","shell.execute_reply":"2025-05-27T07:13:27.467563Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                    2013              2012              2011\n0            net sales            $ 7958            $ 8347            $ 8161\n1     operating profit              1045              1083              1063\n2    operating margins  13.1% ( 13.1 % )  13.0% ( 13.0 % )  13.0% ( 13.0 % )\n3  backlog at year-end             20500             18100             16000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>2013</th>\n      <th>2012</th>\n      <th>2011</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>net sales</td>\n      <td>$ 7958</td>\n      <td>$ 8347</td>\n      <td>$ 8161</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>operating profit</td>\n      <td>1045</td>\n      <td>1083</td>\n      <td>1063</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>operating margins</td>\n      <td>13.1% ( 13.1 % )</td>\n      <td>13.0% ( 13.0 % )</td>\n      <td>13.0% ( 13.0 % )</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>backlog at year-end</td>\n      <td>20500</td>\n      <td>18100</td>\n      <td>16000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## 6. Clean and Format the Table\n\nLoads a sample table as a DataFrame, shortens long column names, removes dollar signs and commas, and attempts to convert values to numeric types for easier processing.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Get one sample\nsample = dataset['train'][0]\nraw_table = sample['table']\n\n# Convert to DataFrame\ndf = pd.DataFrame(raw_table[1:], columns=raw_table[0])\n\n# Optionally shorten long column names\ndf.columns = [col[:30] + '...' if len(col) > 30 else col for col in df.columns]\n\n# Clean $ signs and commas, convert to numbers where possible\nfor col in df.columns:\n    if df[col].dtype == 'object':\n        df[col] = df[col].str.replace(r'[\\$,]', '', regex=True).str.strip()\n        df[col] = pd.to_numeric(df[col], errors='ignore')\n\n# Display cleaned table\ndf.head()\n","metadata":{"id":"Vqd_7CPlgfnq","colab":{"base_uri":"https://localhost:8080/","height":178},"outputId":"d6d54441-b463-48ea-8545-6d511e4261b1","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T07:14:12.683641Z","iopub.execute_input":"2025-05-27T07:14:12.684193Z","iopub.status.idle":"2025-05-27T07:14:12.703108Z","shell.execute_reply.started":"2025-05-27T07:14:12.684169Z","shell.execute_reply":"2025-05-27T07:14:12.702307Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3587919735.py:17: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n  df[col] = pd.to_numeric(df[col], errors='ignore')\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                     october 31 2009  \\\n0  fair value of forward exchange contracts asset...            6427   \n1  fair value of forward exchange contracts after...           20132   \n2  fair value of forward exchange contracts after...  -6781 ( 6781 )   \n\n    november 1 2008  \n0  -23158 ( 23158 )  \n1    -9457 ( 9457 )  \n2  -38294 ( 38294 )  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>october 31 2009</th>\n      <th>november 1 2008</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fair value of forward exchange contracts asset...</td>\n      <td>6427</td>\n      <td>-23158 ( 23158 )</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fair value of forward exchange contracts after...</td>\n      <td>20132</td>\n      <td>-9457 ( 9457 )</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fair value of forward exchange contracts after...</td>\n      <td>-6781 ( 6781 )</td>\n      <td>-38294 ( 38294 )</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## 7. Tokenize Question and Table for the Transformer\n\nThis block uses the `T5Tokenizer` to convert each FinQA sample (question + table) into a format the Transformer model can understand. It flattens the table into a single string, merges it with the question, and tokenizes the result into input IDs and attention masks.\n\n**Purpose**: Prepares raw data for model input — a critical step before training or inference.\n","metadata":{"id":"RQNmdVHZBVPg"}},{"cell_type":"code","source":"from transformers import T5Tokenizer\n\n# Load pretrained tokenizer\ntokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n\n# Sample question and table\nquestion = sample[\"question\"]\ntable_str = \" \".join([\" | \".join(row) for row in sample[\"table\"]])\n\n# Combine question and table for input\ninput_text = f\"question: {question}  context: {table_str}\"\n\n# Tokenize input\ninputs = tokenizer(input_text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n\n# View tokenized inputs\nprint(inputs)\n","metadata":{"id":"pBlceVmxYcGo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e36fca0d-94a7-49d7-e896-a094e85dfbc0","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T15:29:51.467310Z","iopub.execute_input":"2025-05-11T15:29:51.467520Z","iopub.status.idle":"2025-05-11T15:29:51.730700Z","shell.execute_reply.started":"2025-05-11T15:29:51.467498Z","shell.execute_reply":"2025-05-11T15:29:51.729829Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[  822,    10,   125,    19,     8,     8,  1046,  8225,    16,  2464,\n            58,  2625,    10,  1820,     3,    32,    75,   235,  1152,  2664,\n          2464,  1820,     3,  5326, 18247,   209,  2628,  2725,   701,    13,\n          1039,  2509,  8201,  7000,    41,  6283,     3,    61,  1820,  1514,\n          6687,  2555,  1820,  1514,     3,    18,  2773, 26556,    41,  1902,\n         26556,     3,    61,  2725,   701,    13,  1039,  2509,  8201,   227,\n             3,     9,  6389,    41,   335,     3,  1454,     3,    61,    73,\n            89,     9,  1967,   179,  2426,    16,  2959,  7481,  2509,  1917,\n          7000,    41,  6283,     3,    61,  1820,  1514,  2038,   357,  1820,\n          1514,     3,    18,  4240,  3436,    41,     3,  4240,  3436,     3,\n            61,  2725,   701,    13,  1039,  2509,  8201,   227,     3,     9,\n          6389,    41,   335,     3,  1454,     3,    61, 15229,  2426,    16,\n          2959,  7481,  2509,  1917,  6283,  1820,  1514,     3,    18,  3708,\n          4959,    41,     3,  3708,  4959,     3,    61,  1820,  1514,     3,\n          3486,  4613,  4240,    41,   220,  4613,  4240,     3,    61,     1,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]])}\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## 8. Preview Multiple Training Samples\n\nCreates a DataFrame from several FinQA samples, showing the question, answer, rationale, gold indices, and a short preview of the table — useful for quickly understanding data structure and content diversity.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Convert a few training samples into a structured DataFrame\nsamples = [dataset['train'][i] for i in range(5)]\n\n# Create DataFrame with question, answer, rationale (the reasoning steps), and raw table\ndf_samples = pd.DataFrame([{\n    \"question\": s[\"question\"],\n    \"answer\": s[\"answer\"],\n    \"rationale\": s.get(\"rationale\", \"\"),  # Use 'rationale' instead of 'program' and provide default if missing\n    \"gold_inds\": s[\"gold_inds\"],\n    \"table_preview\": \" | \".join([\" | \".join(row) for row in s[\"table\"][:3]]) + \" ...\"\n} for s in samples])\n\ndf_samples","metadata":{"id":"pLvMMu8uYcJt","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"2350275f-16f8-4a3d-c8d6-1138c0ecec0c","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T15:29:51.731439Z","iopub.execute_input":"2025-05-11T15:29:51.731647Z","iopub.status.idle":"2025-05-11T15:29:51.745023Z","shell.execute_reply.started":"2025-05-11T15:29:51.731632Z","shell.execute_reply":"2025-05-11T15:29:51.744256Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                                            question answer rationale  \\\n0          what is the the interest expense in 2009?    380             \n1  during the 2012 year , did the equity awards i...                    \n2  what was the total operating expenses in 2018 ...  41932             \n3  what percentage of total cash and investments ...    53%             \n4    what is the growth rate in net revenue in 2008?  -3.2%             \n\n                                           gold_inds  \\\n0  [if libor changes by 100 basis points , our an...   \n1  [the granted of number of shares ( in thousand...   \n2  [year the 2018 of gallons is 4447 ; the 2018 o...   \n3  [( in millions ) the available-for-sale invest...   \n4  [the 2007 net revenue of amount ( in millions ...   \n\n                                       table_preview  \n0   | october 31 2009 | november 1 2008 | fair va...  \n1   | number of shares ( in thousands ) | weighte...  \n2  year | gallons | average priceper gallon | air...  \n3  ( in millions ) | dec 282013 | dec 292012 | av...  \n4   | amount ( in millions ) | 2007 net revenue |...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n      <th>rationale</th>\n      <th>gold_inds</th>\n      <th>table_preview</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>what is the the interest expense in 2009?</td>\n      <td>380</td>\n      <td></td>\n      <td>[if libor changes by 100 basis points , our an...</td>\n      <td>| october 31 2009 | november 1 2008 | fair va...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>during the 2012 year , did the equity awards i...</td>\n      <td></td>\n      <td></td>\n      <td>[the granted of number of shares ( in thousand...</td>\n      <td>| number of shares ( in thousands ) | weighte...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what was the total operating expenses in 2018 ...</td>\n      <td>41932</td>\n      <td></td>\n      <td>[year the 2018 of gallons is 4447 ; the 2018 o...</td>\n      <td>year | gallons | average priceper gallon | air...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what percentage of total cash and investments ...</td>\n      <td>53%</td>\n      <td></td>\n      <td>[( in millions ) the available-for-sale invest...</td>\n      <td>( in millions ) | dec 282013 | dec 292012 | av...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>what is the growth rate in net revenue in 2008?</td>\n      <td>-3.2%</td>\n      <td></td>\n      <td>[the 2007 net revenue of amount ( in millions ...</td>\n      <td>| amount ( in millions ) | 2007 net revenue |...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"## 9. Preprocessing Function (`preprocess`)\n\nDefines how each sample is tokenized:\n\n- Merges question and table into a single string.\n- Tokenizes the combined text for model input (`input_ids`, `attention_mask`).\n- Separately tokenizes the answer as the target (`labels`).\n- Returns all components as a dictionary of tensors.\n\n**Purpose**: Prepares the input-output pair for the model — what to \"read\" and what to \"predict\".\n","metadata":{"id":"lq3CxxKs4adW"}},{"cell_type":"code","source":"def preprocess(sample):\n    table_str = \" \".join([\" | \".join(row) for row in sample[\"table\"]])\n    input_text = f\"question: {sample['question']}  context: {table_str}\"\n\n    model_inputs = tokenizer(\n        input_text,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=512,\n        return_tensors=\"pt\"\n    )\n\n    # Tokenize the answer as target\n    labels = tokenizer(\n        sample[\"answer\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=64,\n        return_tensors=\"pt\"\n    )[\"input_ids\"]\n\n    model_inputs[\"labels\"] = labels\n    return {k: v.squeeze() for k, v in model_inputs.items()}\n","metadata":{"id":"KOhbNTJDBhFi","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T15:29:51.745792Z","iopub.execute_input":"2025-05-11T15:29:51.745975Z","iopub.status.idle":"2025-05-11T15:29:51.756640Z","shell.execute_reply.started":"2025-05-11T15:29:51.745953Z","shell.execute_reply":"2025-05-11T15:29:51.755959Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## 10. Apply Preprocessing to Training Set\n\nApplies the `preprocess` function to each example in the training set, converting raw samples into tokenized inputs and labels for the model.\n","metadata":{"id":"WgT1pJTt4qGG"}},{"cell_type":"code","source":"tokenized_dataset = dataset[\"train\"].map(preprocess)\n","metadata":{"id":"msWTi9zHBhJJ","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T15:29:51.758769Z","iopub.execute_input":"2025-05-11T15:29:51.759371Z","iopub.status.idle":"2025-05-11T15:29:51.784438Z","shell.execute_reply.started":"2025-05-11T15:29:51.759329Z","shell.execute_reply":"2025-05-11T15:29:51.783903Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## 11. Wrap Tokenized Data in a PyTorch Dataset\n\nCreates a custom `FinQADataset` class to wrap the tokenized Hugging Face dataset in a format compatible with PyTorch’s DataLoader.\n\n**Purpose**: Enables efficient batching and shuffling during training.\n","metadata":{"id":"3V3j4Swq6Mis"}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass FinQADataset(Dataset):\n    def __init__(self, hf_dataset):\n        self.dataset = hf_dataset\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\": torch.tensor(self.dataset[idx][\"input_ids\"]),\n            \"attention_mask\": torch.tensor(self.dataset[idx][\"attention_mask\"]),\n            \"labels\": torch.tensor(self.dataset[idx][\"labels\"]),\n        }\n\n","metadata":{"id":"Ee6DPdlrBhMS","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T15:29:51.785093Z","iopub.execute_input":"2025-05-11T15:29:51.785250Z","iopub.status.idle":"2025-05-11T15:29:51.790149Z","shell.execute_reply.started":"2025-05-11T15:29:51.785238Z","shell.execute_reply":"2025-05-11T15:29:51.789524Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"## 12. Create DataLoader for Training\n\nWraps the `FinQADataset` in a PyTorch `DataLoader` for easy batching and shuffling during training.\n\n**Batch size**: 4  \n**Shuffling**: Enabled for randomness\n","metadata":{"id":"LsySKaWx6VFQ"}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataset = FinQADataset(tokenized_dataset)\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","metadata":{"id":"HWsLyR4PBhXw","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T15:29:51.790761Z","iopub.execute_input":"2025-05-11T15:29:51.790979Z","iopub.status.idle":"2025-05-11T15:29:51.800928Z","shell.execute_reply.started":"2025-05-11T15:29:51.790964Z","shell.execute_reply":"2025-05-11T15:29:51.800241Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"## 13. Load the T5 Model\n\nLoads the pretrained `T5ForConditionalGeneration` model, which includes both encoder and decoder components for sequence-to-sequence tasks like FinQA.\n\n**Model used**: `t5-small`\n","metadata":{"id":"yNAVEwlfj-nT"}},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration\n\n# Load pretrained T5 model (encoder + decoder)\nmodel = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n","metadata":{"id":"w2G5foCzj_Kf","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T15:29:51.801609Z","iopub.execute_input":"2025-05-11T15:29:51.801780Z","iopub.status.idle":"2025-05-11T15:29:51.991871Z","shell.execute_reply.started":"2025-05-11T15:29:51.801760Z","shell.execute_reply":"2025-05-11T15:29:51.991391Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"## 14. Train the T5 Model\n\nRuns a simple training loop for 3 epochs using the `AdamW` optimizer.\n\n- Moves each batch to the model’s device (CPU or GPU)\n- Computes loss, backpropagates, and updates weights\n- Uses `tqdm` to show real-time training progress\n\n**Purpose**: Fine-tunes the T5 model on the FinQA dataset.\n","metadata":{"id":"oJWgL6Zzq41R"}},{"cell_type":"code","source":"import torch\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\n\n# Make sure model is in training mode\nmodel.train()\n\n# Define optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\n# Set number of epochs\nnum_epochs = 3\n\n# Training loop\nfor epoch in range(num_epochs):\n    total_loss = 0\n    loop = tqdm(train_loader, leave=True, desc=f\"Epoch {epoch+1}\")\n\n    for batch in loop:\n        # Move data to the same device as model\n        input_ids = batch[\"input_ids\"].to(model.device)\n        attention_mask = batch[\"attention_mask\"].to(model.device)\n        labels = batch[\"labels\"].to(model.device)\n\n        # Forward pass\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n\n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        loop.set_postfix(loss=loss.item())\n\n    print(f\"Epoch {epoch+1} Average Loss: {total_loss / len(train_loader):.4f}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"_aymyoK0uM0p","outputId":"7013d41e-5031-4b26-af70-30d33280b1c9","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T15:37:30.784287Z","iopub.execute_input":"2025-05-11T15:37:30.784602Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 1563/1563 [1:14:41<00:00,  2.87s/it, loss=0.165]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Average Loss: 0.1961\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 1563/1563 [1:16:46<00:00,  2.95s/it, loss=0.126] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Average Loss: 0.1590\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:  89%|████████▊ | 1385/1563 [1:08:32<08:41,  2.93s/it, loss=0.145] ","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## 15. Set Device for Inference or Training\n\nDetects if a GPU is available and sets the computation device accordingly (`cuda` or `cpu`).\n\n**Purpose**: Ensures the model runs on the most efficient hardware available.\n","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T12:13:23.297492Z","iopub.execute_input":"2025-05-27T12:13:23.297797Z","iopub.status.idle":"2025-05-27T12:13:23.301906Z","shell.execute_reply.started":"2025-05-27T12:13:23.297772Z","shell.execute_reply":"2025-05-27T12:13:23.301090Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 16. Load Fine-Tuned Model and Tokenizer\n\nLoads the previously trained T5 model and tokenizer from the saved directory, then moves the model to the selected device.\n\n**Path**: `/kaggle/input/finqa-model-after-learning`\n","metadata":{}},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained(\"/kaggle/input/finqa-model-after-learning\")\ntokenizer = T5Tokenizer.from_pretrained(\"/kaggle/input/finqa-model-after-learning\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T12:13:26.088782Z","iopub.execute_input":"2025-05-27T12:13:26.089101Z","iopub.status.idle":"2025-05-27T12:13:26.458044Z","shell.execute_reply.started":"2025-05-27T12:13:26.089078Z","shell.execute_reply":"2025-05-27T12:13:26.457433Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## 17. Run Inference on a Sample Question\n\nFormats a sample question and table into a single input, tokenizes it, runs it through the fine-tuned model, and decodes the predicted answer.\n\n\n","metadata":{}},{"cell_type":"code","source":"question = \"What is the net income in 2020?\"\ntable_str = \"Year | Revenue | Net Income 2019 | $100M | $20M 2020 | $120M | $25M\"\n\ninput_text = f\"question: {question} context: {table_str}\"\ninputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\noutputs = model.generate(**inputs)\nanswer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(\"Answer:\", answer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T12:14:47.414513Z","iopub.execute_input":"2025-05-27T12:14:47.415169Z","iopub.status.idle":"2025-05-27T12:14:48.814434Z","shell.execute_reply.started":"2025-05-27T12:14:47.415139Z","shell.execute_reply":"2025-05-27T12:14:48.813737Z"}},"outputs":[{"name":"stdout","text":"Answer: $ 900 million\n","output_type":"stream"}],"execution_count":8}]}